{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversational Threads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many LLM applications have a chatbot-like interface in which the user and the LLM application engage in a multi-turn conversation. In order to track these conversations, you can use the Threads feature in LangSmith.\n",
    "\n",
    "This is relevant to our RAG application, which should maintain context from prior conversations with users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group traces into threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Thread is a sequence of traces representing a single conversation. Each response is represented as its own trace, but these traces are linked together by being part of the same thread.\n",
    "\n",
    "To associate traces together, you need to pass in a special metadata key where the value is the unique identifier for that thread.\n",
    "\n",
    "The key value is the unique identifier for that conversation. The key name should be one of:\n",
    "\n",
    "- session_id\n",
    "- thread_id\n",
    "- conversation_id.\n",
    "\n",
    "The value should be a UUID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "thread_id = uuid.uuid4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "openai_client = OpenAI()\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    rag_system_prompt = \"\"\"You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise.\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": rag_system_prompt\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_openai(\n",
    "    messages: List[dict], model: str = \"gpt-4o-mini\", temperature: float = 0.0\n",
    ") -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's run our application twice with this thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To add metadata to a trace in LangSmith, you need to include a dictionary of key-value pairs when creating the trace. This metadata can store additional information about the trace, such as the environment or user details. Ensure that the same metadata is also attached to the corresponding run for better tracking.\n"
     ]
    }
   ],
   "source": [
    "question = \"How do I add metadata to a Trace?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can add tags to a trace in LangSmith by sending arbitrary metadata and tags along with the trace. Tags are strings used to categorize or label the trace, while metadata is a dictionary of key-value pairs for additional information. For detailed instructions, refer to the documentation on adding metadata and tags to traces.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I add tags to a Trace?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"thread_id\": thread_id}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look in LangSmith!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Turn 1: Hi Aditya, I can help with your refund request. Please provide your order number.\n",
      "Turn 2: Hi Aditya, let me check your shipping status. What's your tracking number?\n",
      "Turn 3: Hi Aditya, how else can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "import uuid\n",
    "\n",
    "# Create a unique thread ID for customer conversation\n",
    "customer_thread = uuid.uuid4()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def customer_support_bot(user_query: str, customer_name: str):\n",
    "    \"\"\"\n",
    "    Simple customer support bot that maintains conversation thread\n",
    "    \"\"\"\n",
    "    if \"refund\" in user_query.lower():\n",
    "        return f\"Hi {customer_name}, I can help with your refund request. Please provide your order number.\"\n",
    "    elif \"shipping\" in user_query.lower():\n",
    "        return f\"Hi {customer_name}, let me check your shipping status. What's your tracking number?\"\n",
    "    else:\n",
    "        return f\"Hi {customer_name}, how else can I assist you today?\"\n",
    "\n",
    "# Simulate conversation thread\n",
    "queries = [\n",
    "    \"I need help with a refund\",\n",
    "    \"What's the status of my shipping?\",\n",
    "    \"Thank you for your help\"\n",
    "]\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    response = customer_support_bot(\n",
    "        query, \n",
    "        \"Aditya\",\n",
    "        langsmith_extra={\"metadata\": {\"thread_id\": customer_thread, \"turn\": i+1}}\n",
    "    )\n",
    "    print(f\"Turn {i+1}: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Try grilled chicken with herbs\n",
      "Step 2: Roasted vegetables with spices work well (adapted for vegan)\n",
      "Step 3: How about garlic pasta with olive oil (adapted for gluten-free)\n"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "import uuid\n",
    "\n",
    "# Create thread for cooking session\n",
    "cooking_session = uuid.uuid4()\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def recipe_helper(ingredient: str, dietary_restriction: str = \"\"):\n",
    "    \"\"\"\n",
    "    Recipe assistant that provides suggestions based on ingredients\n",
    "    \"\"\"\n",
    "    recipes = {\n",
    "        \"chicken\": \"Try grilled chicken with herbs\",\n",
    "        \"pasta\": \"How about garlic pasta with olive oil\",\n",
    "        \"vegetables\": \"Roasted vegetables with spices work well\"\n",
    "    }\n",
    "    \n",
    "    base_recipe = recipes.get(ingredient.lower(), \"I suggest a simple stir-fry\")\n",
    "    \n",
    "    if dietary_restriction:\n",
    "        return f\"{base_recipe} (adapted for {dietary_restriction})\"\n",
    "    return base_recipe\n",
    "\n",
    "# Multi-turn cooking conversation\n",
    "conversation = [\n",
    "    (\"chicken\", \"\"),\n",
    "    (\"vegetables\", \"vegan\"),\n",
    "    (\"pasta\", \"gluten-free\")\n",
    "]\n",
    "\n",
    "for i, (ingredient, restriction) in enumerate(conversation):\n",
    "    suggestion = recipe_helper(\n",
    "        ingredient, \n",
    "        restriction,\n",
    "        langsmith_extra={\"metadata\": {\"thread_id\": cooking_session, \"step\": i+1}}\n",
    "    )\n",
    "    print(f\"Step {i+1}: {suggestion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
